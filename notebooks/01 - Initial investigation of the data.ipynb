{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('assistment_data_corrected.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401756 entries, 0 to 401755\n",
      "Data columns (total 30 columns):\n",
      "order_id                401756 non-null int64\n",
      "assignment_id           401756 non-null int64\n",
      "user_id                 401756 non-null int64\n",
      "assistment_id           401756 non-null int64\n",
      "problem_id              401756 non-null int64\n",
      "original                401756 non-null int64\n",
      "correct                 401756 non-null int64\n",
      "attempt_count           401756 non-null int64\n",
      "ms_first_response       401756 non-null int64\n",
      "tutor_mode              401756 non-null object\n",
      "answer_type             401756 non-null object\n",
      "sequence_id             401756 non-null int64\n",
      "student_class_id        401756 non-null int64\n",
      "position                401756 non-null int64\n",
      "type                    401756 non-null object\n",
      "base_sequence_id        401756 non-null int64\n",
      "skill_id                338001 non-null float64\n",
      "skill_name              325637 non-null object\n",
      "teacher_id              401756 non-null int64\n",
      "school_id               401756 non-null int64\n",
      "hint_count              401756 non-null int64\n",
      "hint_total              401756 non-null int64\n",
      "overlap_time            401756 non-null int64\n",
      "template_id             401756 non-null int64\n",
      "answer_id               45454 non-null float64\n",
      "answer_text             312548 non-null object\n",
      "first_action            401756 non-null int64\n",
      "bottom_hint             67044 non-null float64\n",
      "opportunity             401756 non-null int64\n",
      "opportunity_original    328291 non-null float64\n",
      "dtypes: float64(4), int64(21), object(5)\n",
      "memory usage: 92.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An explanation of the fields\n",
    "This is taken from [the ASSISTments data website](https://sites.google.com/site/assistmentsdata/how-to-interpret).\n",
    "* `order_id`: These id's are chronological, and refer to the id of the original problem log.\n",
    "* `assignment_id`: Each time a teacher assigns a problem set that assignment gets a separate number. This is that number. \n",
    "* `user_id`: The ID of the student doing the problem.\n",
    "* `assistment_id`: Similar to problem_id. The ID of a problem one will see in the builder. If a problem has multiple main problems and/or scaffolding, everything relating to one problem is called an assistment and has the same assistment_id. If you see problem logs with the same assistment number, they are multiple main problems(or scaffolding problems) that are part of the same overarching problem.\n",
    "* `problem_id`: The ID of the problem. If a problem has multiple main problems, each multiple main problem will have a different problem_id.\n",
    "* `original`: \n",
    "  * 1 = Main problem\n",
    "  * 0 = Scaffolding problem  \n",
    "    If a problem has scaffolding and the student answers incorrectly or asks for the problem to be broken into steps, a new problem will be created called a scaffolding problem. This creates a separate problem log row in the file with the variable original = 0.\n",
    "* `correct`: \n",
    "  * 1 = Correct on first attempt\n",
    "  * 0 = Incorrect on first attempt, or asked for help  \n",
    "This column is often the target for prediction. (Minor note: Neil Heffernan notes that while this is true most of the time, we also have Essay questions that teachers can grade.  Neil thinks that if this value is say .25 that means the teacher gave it a 1 our of 4.)\n",
    "* `attempt_count`: Number of attempts(number of times a student entered an answer)\n",
    "* `ms_first_response`: Time between start time and first student action(asking for hint or entering an answer) (in milliseconds)\n",
    "* `tutor_mode`: Tutor, test mode, pre-test, or post-test\n",
    "* `answer_type`: Unknown\n",
    "* `sequence_id`: ASSISTments is very confusing in how they use \"Problem Set\" and \"Sequence\".  The same object that is called a \"Sequence\" in the database is exposed to teachers as a \"Problem Set\".  If you have a sequence ID, you can use the converter [here](http://users.wpi.edu/~xxiong/app.html) to get the corresponding problem set number to use ASSISTments and see exactly what the content looked like.\n",
    "* `student_class_id`: The ID of the class, the same for all students in the same class.  If you want to heiricharchila liearn modeling you can use this for the class ID.  We can also give you a teacher ID.  You might also want to look at section ID\n",
    "* `position`: The placement of the assignment within the teacher's assignment page (i.e., 5 means the 5th problem set assigned)\n",
    "* `type`: Determined by assignment type id. Usually ClassAssignment, but sometimes ARRS or remedial.\n",
    "* `base_sequence_id`: This is to account for if a sequence has been copied. This will point to the original copy, or be the same as sequence_id if it hasn't been copied.\n",
    "* `skill_id`: ID of the skill associated with the problem. For the skill builder dataset, different skills for the same data record are in different rows. This means if a student answers a multi skill question, this record is duplicated several times, and each duplication is tagged with one of the multi skills. For the non skill builder dataset, different skills for the same data record are in the same row, separated with comma.\n",
    "* `skill_name`: Skill name associated with the problem.\n",
    "* `teacher_id`: Unknown\n",
    "* `school_id`: ID number for the school\n",
    "* `hint_count`: Number of hints a student asked for during the duration of the problem.\n",
    "* `hint_total`: Number of possible hints on this problem.  We tell you the total number of hints so you can compute something like a % of hints used.  Not all problems have all the same number of hints. \n",
    "* `overlap_time`: Number of possible hints on this problem.  We tell you the total number of hints so you can compute something like a % of hints used.  Not all problems have all the same number of hints. This field is often computed incorrectly. Many data sets display overlap time the same as the first response time. You could compute overlap time using other fields, like using the state time of two problems. \n",
    "* `template_id`: The template ID of the ASSISTment. ASSISTments with the same template ID have similar questions.\n",
    "* `answer_id`: Only exists for multiple choice or choose all that apply questions. \n",
    "  * A number =  the answer the student put in corresponds with one of the answers for that problem\n",
    "  * 0 or empty = the student put an answer not corresponding with one of the answers for that problem\n",
    "* `answer_text`: The answer the student entered. Or the value the student selected in a multiple choice or choose all that apply problem.\n",
    "* `first_action`: \n",
    "  * 0 = attempt\n",
    "  * 1 = hint\n",
    "  * 2 = scaffolding\n",
    "  * empty = student clicked on the problem but did nothing else\n",
    "* `bottom_hint`: \n",
    "  * 1 = The student asked for the bottom out hint\n",
    "  * 0 = The student did not ask for the bottom out hint.\n",
    "  * If this is blank it means the student did not ask for a hint.  Remember that for scaffolding questions they can not get a hint.\n",
    "  * The bottom out hint is the last hint for a problem and will generally contain the problemâ€™s answer.\n",
    "* `opportunity`: The number of opportunities the student has to practice on this skill. For the skill builder dataset, opportunities for different skills of the same data record are in different rows. This means if a student answers a multi skill question, this record is duplicated several times, and each duplication is tagged with one of the multi skills and the corresponding opportunity count.\n",
    "* `opportunity_original`: The number of opportunities the student has to practice on this skill counting only original problems. For the skill builder dataset, original opportunities for different skills of the same data record are in different rows. This means if a student answers a multi skill question, this record is duplicated several times, and each duplication is tagged with one of the multi skills and the corresponding original opportunity count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_time = df['overlap_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = df['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_overlap = df['overlap_time'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = [0 if x < median_overlap else 1 for x in overlap_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23279380539926584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(overlap, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['skill_id'])]\n",
    "groups = list(df.groupby(['user_id', 'skill_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41982"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(groups[9][1]['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WebApp.server.BKT import BKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BKT(np.array(groups[9][1]['correct']).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, pi, B = model.get_model_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+000 2.00698872e-112]\n"
     ]
    }
   ],
   "source": [
    "# Start probabilities\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.17179653e-15 1.00000000e+00]\n",
      " [1.17179653e-15 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Transition probabilities\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+000 3.51538960e-015]\n",
      " [6.68996241e-113 1.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "# Emission probabilities\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the primary diagonal elements are both 1, my guess is that for this particular run, the hidden state 0 (the model's internal state 0) corresponds to observed state 0 (unlearned), and same with state 1. Now looking at the transition probabilities, it says that p(unlearned --> learned) = 1 and p(learned --> learned) = 1. This makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
